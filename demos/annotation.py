import json

from dotenv import load_dotenv

import palimpzest as pz
from palimpzest.core.data.validationdata import ValidationData
from palimpzest.sets import Dataset
from palimpzest.tools.score_fn import bleu_scorer

load_dotenv()


# define the fields we wish to compute
paper_cols = [
    {"name": "PaperIdentifier", "type": str, "desc": "The title of the paper"},
    {"name": "TargetMaterial", "type": str, "desc": "The novel material being generated by carbonation"},
    {"name": "MainComponents", "type": str, "desc": "the main components of the material generated by carbonation"},
    {"name": "Strength", "type": str, "desc": "the highest strength of the material generated by carbonation"},
]

# lazily construct the computation to get emails about holidays sent in July
#dataset = Dataset("testdata/matsci_pdfs/")
dataset = Dataset("testdata/Sample_Papers_NLP_tiny")
dataset = dataset.sem_add_columns(paper_cols)

# execute the computation w/the MaxQuality policy
config = pz.QueryProcessorConfig(verbose=True, execution_strategy="parallel")
val_data = ValidationData(".pz_logs/execution_id_42e8004490/annotated_real.json")
val_data.set_score_fn("TargetMaterial", bleu_scorer)
val_data.set_score_fn("MainComponents", bleu_scorer)
val_data.set_score_fn("Strength", bleu_scorer)
config.val_data = val_data

config.processing_strategy = "mab_sentinel"

output = dataset.run(config, k=3, j=3, sample_budget=3)

# display output (if using Jupyter, otherwise use print(output_df))
output_df = output.to_df(cols=["PaperIdentifier", "TargetMaterial", "MainComponents", "filename", "Strength"])
print(output_df)
output_df.to_csv('recipes.csv', index=False)
with open('execution_stats.json', 'w') as f:
    f.write(json.dumps(output.execution_stats.to_json(), indent=2))
